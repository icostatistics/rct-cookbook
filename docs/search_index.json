[["index.html", "Analyzing RCTs: A Cookbook Chapter 1 Preface 1.1 Structure of the book 1.2 Acknowledgements", " Analyzing RCTs: A Cookbook Inge Christoffer Olsen 2024-11-27 Chapter 1 Preface This is a working document describing how I usually analyse and present randomized controlled trials (RCTs), both in Stata and R. It is mainly a repository for code I use and need to refer to instead of searching through old code, but it could be useful for other as well. I am quite new to R, and have embraced the tidyverse style of coding. The graphics are a mostly created using ggplot2, but lately I have also started using the ggformula package. The “book” is written in RMarkdown with bookdown. 1.1 Structure of the book The structure of the book is not very sophisticated. First there is an introduction where I introduce the concept of an RCT, and then I simualte a trial to be used in the continuation of the book. Chapter 3 and 4 are description on how to analyse continuous and dichotomous endpoints, both for single and repeated follow-up observations. The plan is to include also a chapter on time to event endpoints and sample size calculations. 1.2 Acknowledgements "],["intro.html", "Chapter 2 Introduction 2.1 Trial Flow 2.2 Simulated dataset", " Chapter 2 Introduction 2.1 Trial Flow The typical flow for an RCT should be something like: Through hypothesis generating research, by clinical experience or sheer luck, a hypothesis has been developed. The hypothesis indicates that an intervention treatment is either superior, non-inferior or equivalent to an existing treatment (the control). A Population, the Intervention, the Control group and the Outcome measure (PICO) has been identified A protocol has been written, detailing the background, research aim, the population, the intervention and control treatment, which assessments will be done when and how the data will be collected, how safety will be assessed, and the principles on how the data will be analysed. All formal requirements has been met and the data capture method is set up. The first patient is included in the study. About 3-6 months prior to database lock, the statistical analysis plan (SAP) and corresponding code should be started. Regardless of blinding, a separate randomisation list, not equal to the actual allocation list, should be used to avoid biased analysis decisions. The coding should result in a generated report to be discussed with the clinician. When all data has been gathered and the database locked, the allocation list is opended, included in the code, and all code is run. The generated report should include all results required in the SAP. The statistician should by the involvement be a co-author with all requirements. The study is published. 2.2 Simulated dataset To show the different analyses methods, we need to simulate an RCT. I use Stata to create the simulated dataset, mainly because it is easier to get data from Stata to R than the other way around. We simulate a trial with repeated measurements for a continuous and a dichotomous endpoint in addition to a time to event endpoint. We include site as a strata in the randomisation (influencing the outcome), and an independent covariate which is highly predictive of the outcome. *Setup the randomisation with strata and blocks ralloc block bsize trt, nsubj(50) sav(stata/rct) ntreat(2) ratio(1) osize(2) init(4) seed(1914) strata(4) *Clean up and add repeated time points use stata/rct, clear label drop _all gen pid = _n replace trt=trt-1 label def trt 0 &quot;Placebo&quot; 1 &quot;Active&quot; label val trt trt rename StratID site drop block bsize Seq* order pid site trt sort pid expand 4 sort pid by pid: gen time=_n-1 *Simulate the normaly distributed continuous endpoints *Generate the random intercept and residual gen incept0 = rnormal(0,1) if time == 0 by pid: egen incept = max(incept0) drop incept0 gen covar0 = round(rnormal(6,2),0.1) if time == 0 by pid: egen covar = max(covar0) drop covar0 gen resid = rnormal(0,1) *Set the mean by time and treatment generate mean = cond(trt==0 &amp; time==0, 4, cond(trt==0 &amp; time==1, 5.5, cond(trt==0 &amp; time==2, 7.2, cond(trt==0 &amp; time==3, 8, cond(trt==1 &amp; time==0, 4, cond(trt==1 &amp; time==1, 4.4, cond(trt==1 &amp; time==2, 5, cond(trt==1 &amp; time==3, 5.5,.)))))))) *Set the mean by site and baseline covariate gen site_mean = site/2 - 1.25 *Generate the outcome gen contout = 10 + incept + mean + site_mean + covar + resid replace contout = round(contout,0.1) gen baseline0 = contout if time == 0 by pid: egen contbl = max(baseline0) drop baseline0 *Simulate the categorical outcome by latent variable gen catout = -10 + incept + mean + site_mean + covar + rlogistic() &gt; 0 label def catout 0 &quot;Negative&quot; 1 &quot;Positive&quot; label val catout catout *Remove all observations with a positive categorical outcome at baseline to simulate a selection criteria by pid: egen catoutbl = max(cond(time==0,catout,.)) drop if catoutbl==1 *Simulate a time to event outcome with a weibull distribution gen timemean = 2 + incept + mean + site_mean + covar if time == 0 gen timeout0 = rweibull(1.5,timemean) gen censor0 = rnormal(12,1) if time == 0 gen timecens0 = timeout &lt; censor0 if time == 0 replace timeout = censor0 if timecens0 == 0 by pid: egen timeout = max(timeout0) by pid: egen timecens = max(timecens0) replace timeout = round(timeout,0.1) label def cens 0 &quot;Censored&quot; 1 &quot;Event&quot; label val timecens cens *Clean up and name variables drop incept mean resid site_mean timemean - timecens0 catoutbl order pid - covar contbl label var pid &quot;Patient identifier&quot; label var site &quot;Site&quot; label var trt &quot;Treatment&quot; label var time &quot;Time point2&quot; label var covar &quot;Continuous baseline covariate&quot; label var contbl &quot;Baseline value continuous outcome&quot; label var contout &quot;Continuous outcome&quot; label var catout &quot;Categorical outcome&quot; label var timeout &quot;Time to event outcome&quot; label var timecens &quot;Censoring/event identifier&quot; save stata/rct, replace The resulting dataset then looks like this (without the Stata variable names and labels): pid site trt time covar contbl contout catout timeout timecens 1 1 Active 0 6.8 20.2 20.2 Negative 9.5 1 1 1 Active 1 6.8 20.2 18.1 Positive 9.5 1 1 1 Active 2 6.8 20.2 19.4 Positive 9.5 1 1 1 Active 3 6.8 20.2 20.0 Positive 9.5 1 4 1 Placebo 0 7.9 20.0 20.0 Negative 4.6 1 4 1 Placebo 1 7.9 20.0 20.9 Positive 4.6 1 4 1 Placebo 2 7.9 20.0 23.5 Positive 4.6 1 4 1 Placebo 3 7.9 20.0 23.8 Positive 4.6 1 The data can be visualised like this: rct %&gt;% group_by(trt,time) %&gt;% summarise(mean=mean(contout),sd=sd(contout)) %&gt;% ggplot(mapping=aes(x=time, y=mean, color=trt,group=trt,ymin = mean-sd, ymax=mean+sd)) + geom_point() + geom_errorbar(width=0.2) + geom_line() + theme_classic() + ggtitle(&quot;Mean outcome with standard deviations&quot;) + scale_colour_brewer(palette = &quot;Set1&quot;) ## `summarise()` has grouped output by &#39;trt&#39;. You can override using the ## `.groups` argument. "],["continuous-endpoints.html", "Chapter 3 Continuous endpoints 3.1 Single follow-up 3.2 Repeated follow-up", " Chapter 3 Continuous endpoints 3.1 Single follow-up When the outcome consists of a single follow-up assessment of the continuous endpoint, the main method I use is Analysis of Covariance. According to the EMAs Guideline on adjustment for baseline covariates in clinical trials we should adjust for site in multicentre trial, any stratification factors in the randomisation in addition to pre-specified covariates with evidence of strong or moderate association between the covariate and the primary outcome measure. Usually this also means the baseline observation of the outcome. In our simulated data set this means to adjust for site, contbl and covar variables. In this example we define that the primary outcome is the continuous outcome at time 3. 3.1.1 Stata code use stata/rct, clear regress contout i.trt i.site covar contbl if time==3 (all strata combined) Source | SS df MS Number of obs = 98 -------------+---------------------------------- F(6, 91) = 67.55 Model | 454.530038 6 75.7550064 Prob &gt; F = 0.0000 Residual | 102.049964 91 1.12142818 R-squared = 0.8166 -------------+---------------------------------- Adj R-squared = 0.8046 Total | 556.580002 97 5.73793817 Root MSE = 1.059 ------------------------------------------------------------------------------ contout | Coefficient Std. err. t P&gt;|t| [95% conf. interval] -------------+---------------------------------------------------------------- trt | Active | -2.768593 .2162162 -12.80 0.000 -3.198079 -2.339106 | site | 2 | .0464146 .3171924 0.15 0.884 -.5836491 .6764783 3 | .194252 .2832692 0.69 0.495 -.3684276 .7569315 4 | .7040756 .3356689 2.10 0.039 .0373106 1.370841 | covar | .5580744 .0882877 6.32 0.000 .3827017 .7334471 contbl | .3812488 .0813377 4.69 0.000 .2196815 .5428161 _cons | 12.60568 1.165712 10.81 0.000 10.29013 14.92122 ------------------------------------------------------------------------------ Note that we here looked at the outcome at time 3 as the primary outcome. It does not matter if we use this or the change from baseline to time 3, due to the baseline adjustment: use stata/rct, clear gen diff = contout - contbl regress diff i.trt i.site covar contbl if time==3 (all strata combined) Source | SS df MS Number of obs = 98 -------------+---------------------------------- F(6, 91) = 40.55 Model | 272.859876 6 45.476646 Prob &gt; F = 0.0000 Residual | 102.049964 91 1.12142818 R-squared = 0.7278 -------------+---------------------------------- Adj R-squared = 0.7099 Total | 374.90984 97 3.8650499 Root MSE = 1.059 ------------------------------------------------------------------------------ diff | Coefficient Std. err. t P&gt;|t| [95% conf. interval] -------------+---------------------------------------------------------------- trt | Active | -2.768593 .2162162 -12.80 0.000 -3.198079 -2.339106 | site | 2 | .0464146 .3171924 0.15 0.884 -.5836491 .6764783 3 | .194252 .2832692 0.69 0.495 -.3684276 .7569315 4 | .7040756 .3356689 2.10 0.039 .0373106 1.370841 | covar | .5580744 .0882877 6.32 0.000 .3827017 .7334471 contbl | -.6187512 .0813377 -7.61 0.000 -.7803185 -.4571839 _cons | 12.60568 1.165712 10.81 0.000 10.29013 14.92122 ------------------------------------------------------------------------------ We see that the only difference is that the baseline parameter estimate shifts with one unit. 3.1.2 R code rct &lt;- read_dta(&quot;stata/rct.dta&quot;) %&gt;% modify_at(c(&quot;trt&quot;,&quot;catout&quot;), haven::as_factor, levels = &quot;labels&quot;) %&gt;% modify_at(c(&quot;site&quot;,&quot;time&quot;), haven::as_factor) rct %&gt;% filter(time==3) %&gt;% lm(contout ~ trt + site + covar + contbl, data=.) %&gt;% summary Call: lm(formula = contout ~ trt + site + covar + contbl, data = .) Residuals: Min 1Q Median 3Q Max -2.35594 -0.68326 0.00278 0.73595 1.98465 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 12.60568 1.16571 10.814 &lt; 2e-16 *** trtActive -2.76859 0.21622 -12.805 &lt; 2e-16 *** site2 0.04641 0.31719 0.146 0.8840 site3 0.19425 0.28327 0.686 0.4946 site4 0.70408 0.33567 2.098 0.0387 * covar 0.55807 0.08829 6.321 9.46e-09 *** contbl 0.38125 0.08134 4.687 9.68e-06 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 1.059 on 91 degrees of freedom Multiple R-squared: 0.8166, Adjusted R-squared: 0.8046 F-statistic: 67.55 on 6 and 91 DF, p-value: &lt; 2.2e-16 We see that the parameter estimates are identical. 3.1.3 Reporting According to the CONSORT Statement item 17a: &gt; For each outcome, study results should be reported as a summary of the outcome in each group (for example, the number of participants with or without the event and the denominators, or the mean and standard deviation of measurements), together with the contrast between the groups, known as the effect size. For the single follow-up we present the mean and standard deviaiton for the outcome in addition to the effect size at follow-up (time 3). There is some coding to get the format right, but the nice thing is that the table could be pasted directly into the article. There are many ways to program this, the below example is one way. #Two functions to produce the mean (sd) and est (lci to uci) output-------------------- get_meansd &lt;- function(m, s, d=2){ paste(round(m, digits=d),&quot; (&quot;,round(s,digits=d),&quot;)&quot;) } get_estci &lt;- function(e, l, u, d=2){ paste(round(e, digits=d), &quot; (&quot;, round(l, digits=d), &quot; to &quot;, round(u, digits=d),&quot;)&quot;) } # Compile the summary measures--------------------------------------------------------- single_cont_sum &lt;- rct %&gt;% group_by(trt) %&gt;% filter(time==3) %&gt;% select(contout, trt) %&gt;% summarise_all(list(~mean(.),~sd(.))) %&gt;% mutate(txt1=get_meansd(mean,sd)) %&gt;% select(trt,txt1) %&gt;% spread(key=trt,value=txt1) # Compile the estimates -------------------------------------------------------------- single_cont_est &lt;- rct %&gt;% filter(time==3) %&gt;% lm(contout ~ trt + site + covar + contbl, data=.) %&gt;% tidy(conf.int=TRUE) %&gt;% filter(term==&quot;trtActive&quot;) %&gt;% mutate(txt2=get_estci(estimate,conf.low,conf.high)) %&gt;% select(term,txt2) # Combine and produce the table ----------------------------------------------------- single_cont_sum %&gt;% bind_cols(single_cont_est) %&gt;% mutate(txt=&quot;Outcome at time 3, mean (sd)&quot;) %&gt;% select(txt,Active, Placebo, txt2) %&gt;% kable(col.names=c(&quot;Outcome&quot;, &quot;Active&quot;, &quot;Placebo&quot;, &quot;Effect size with 95% confidence limits&quot;)) Outcome Active Placebo Effect size with 95% confidence limits Outcome at time 3, mean (sd) 19.88 ( 2.05 ) 22.3 ( 2.09 ) -2.77 ( -3.2 to -2.34 ) 3.2 Repeated follow-up When the measurements are repeated, I usually use mixed models to model the data. The challenge with mixed models is that the effect size can be estimated in several ways, depending on the model specification. 3.2.1 Simple model The simplest model is a model with random intercept and treatment, time and other baseline covariates as fixed effects. \\[ Y_{ij} = \\mu_j + A_i + \\mu_{trt} + \\mu_{strat} + a_1 X_1 + \\epsilon_{ij} \\] where \\(Y_{ij}\\) is the contiuous outcome for individual \\(i\\) at time \\(j\\), \\(\\mu_j\\) is the overall mean at time \\(j\\), \\(A_i\\) is the random intercept for individual \\(i\\), \\(\\mu_{trt}\\) is the mean treatment effect, \\(\\mu_{strat}\\) is the mean effect of strata, \\(a_1\\) is the slope parameter of baseline covariate \\(X_1\\), and \\(\\epsilon_{ij}\\) is the residual. The expression is sloppy, but should be readable. In Stata, this model is coded as use stata/rct, clear mixed contout i.trt i.site i.time covar || pid: (all strata combined) Performing EM optimization ... Performing gradient-based optimization: Iteration 0: Log likelihood = -657.45638 Iteration 1: Log likelihood = -657.45638 Computing standard errors ... Mixed-effects ML regression Number of obs = 392 Group variable: pid Number of groups = 98 Obs per group: min = 4 avg = 4.0 max = 4 Wald chi2(8) = 668.05 Log likelihood = -657.45638 Prob &gt; chi2 = 0.0000 ------------------------------------------------------------------------------ contout | Coefficient Std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- trt | Active | -1.429745 .1959578 -7.30 0.000 -1.813815 -1.045675 | site | 2 | .6526838 .2761648 2.36 0.018 .1114107 1.193957 3 | .5751011 .2484525 2.31 0.021 .0881431 1.062059 4 | .9060635 .2962487 3.06 0.002 .3254268 1.4867 | time | 1 | .9346939 .1621317 5.77 0.000 .6169216 1.252466 2 | 2.069388 .1621317 12.76 0.000 1.751615 2.38716 3 | 2.689796 .1621317 16.59 0.000 2.372024 3.007568 | covar | .8633823 .0519317 16.63 0.000 .761598 .9651666 _cons | 14.55194 .3117202 46.68 0.000 13.94098 15.1629 ------------------------------------------------------------------------------ ------------------------------------------------------------------------------ Random-effects parameters | Estimate Std. err. [95% conf. interval] -----------------------------+------------------------------------------------ pid: Identity | var(_cons) | .6013744 .1345595 .3878697 .9324039 -----------------------------+------------------------------------------------ var(Residual) | 1.288047 .1062364 1.095786 1.514041 ------------------------------------------------------------------------------ LR test vs. linear model: chibar2(01) = 46.95 Prob &gt;= chibar2 = 0.0000 In R this the model is coded as rct %&gt;% lmer(contout ~ trt + site + time + covar + (1|pid),data=., REML=FALSE) %&gt;% summary(correlation=FALSE) Linear mixed model fit by maximum likelihood [&#39;lmerMod&#39;] Formula: contout ~ trt + site + time + covar + (1 | pid) Data: . AIC BIC logLik deviance df.resid 1336.9 1380.6 -657.5 1314.9 381 Scaled residuals: Min 1Q Median 3Q Max -3.4684 -0.5939 0.0717 0.6466 2.4636 Random effects: Groups Name Variance Std.Dev. pid (Intercept) 0.6014 0.7755 Residual 1.2880 1.1349 Number of obs: 392, groups: pid, 98 Fixed effects: Estimate Std. Error t value (Intercept) 14.55194 0.31172 46.683 trtActive -1.42975 0.19596 -7.296 site2 0.65268 0.27616 2.363 site3 0.57510 0.24845 2.315 site4 0.90606 0.29625 3.058 time1 0.93469 0.16213 5.765 time2 2.06939 0.16213 12.764 time3 2.68980 0.16213 16.590 covar 0.86338 0.05193 16.625 Note that we need to specify “REML=FALSE” to produce Maximum Likelihood estimates to be consistent with the Stata estimates. This is clearly not a good model since it assumes that the treatment effect is the same at all timepoints (including baseline). Since we should assume no treatment difference at baseline, the model is clearly wrong. We see this when we plot the model estimates through the “margins” and “marginsplot” procedures in Stata, and the “marginaleffects”-package in R. The “marginaleffects”-package is heavily influenced by Stata. use stata/rct, clear mixed contout i.trt i.site i.time covar || pid: *Compute the marginal estimates by time and treatment margins time#trt *Plot the marginal estimates. Note that the arguments after the comma is just to prettify the plot. marginsplot, graphregion(color(white)) graphregion(color(white)) plotregion(color(white)) ytitle(&quot;Marginal estimates&quot;) ylabel(,nogrid) legend(region(color(none) lstyle(none)) cols(1) ring(0) bplacement(nwest)) title(&quot;&quot;) graph export stata/figures/cont_fig1.pdf, replace (all strata combined) Performing EM optimization ... Performing gradient-based optimization: Iteration 0: Log likelihood = -657.45638 Iteration 1: Log likelihood = -657.45638 Computing standard errors ... Mixed-effects ML regression Number of obs = 392 Group variable: pid Number of groups = 98 Obs per group: min = 4 avg = 4.0 max = 4 Wald chi2(8) = 668.05 Log likelihood = -657.45638 Prob &gt; chi2 = 0.0000 ------------------------------------------------------------------------------ contout | Coefficient Std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- trt | Active | -1.429745 .1959578 -7.30 0.000 -1.813815 -1.045675 | site | 2 | .6526838 .2761648 2.36 0.018 .1114107 1.193957 3 | .5751011 .2484525 2.31 0.021 .0881431 1.062059 4 | .9060635 .2962487 3.06 0.002 .3254268 1.4867 | time | 1 | .9346939 .1621317 5.77 0.000 .6169216 1.252466 2 | 2.069388 .1621317 12.76 0.000 1.751615 2.38716 3 | 2.689796 .1621317 16.59 0.000 2.372024 3.007568 | covar | .8633823 .0519317 16.63 0.000 .761598 .9651666 _cons | 14.55194 .3117202 46.68 0.000 13.94098 15.1629 ------------------------------------------------------------------------------ ------------------------------------------------------------------------------ Random-effects parameters | Estimate Std. err. [95% conf. interval] -----------------------------+------------------------------------------------ pid: Identity | var(_cons) | .6013744 .1345595 .3878697 .9324039 -----------------------------+------------------------------------------------ var(Residual) | 1.288047 .1062364 1.095786 1.514041 ------------------------------------------------------------------------------ LR test vs. linear model: chibar2(01) = 46.95 Prob &gt;= chibar2 = 0.0000 Predictive margins Number of obs = 392 Expression: Linear prediction, fixed portion, predict() ------------------------------------------------------------------------------ | Delta-method | Margin std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- time#trt | 0#Placebo | 19.12477 .1687953 113.30 0.000 18.79394 19.45561 0#Active | 17.69503 .1711009 103.42 0.000 17.35968 18.03038 1#Placebo | 20.05947 .1687953 118.84 0.000 19.72863 20.3903 1#Active | 18.62972 .1711009 108.88 0.000 18.29437 18.96507 2#Placebo | 21.19416 .1687953 125.56 0.000 20.86333 21.52499 2#Active | 19.76442 .1711009 115.51 0.000 19.42906 20.09977 3#Placebo | 21.81457 .1687953 129.24 0.000 21.48374 22.1454 3#Active | 20.38482 .1711009 119.14 0.000 20.04947 20.72018 ------------------------------------------------------------------------------ Variables that uniquely identify margins: time trt file stata/figures/cont_fig1.pdf saved as PDF format knitr::include_graphics(&quot;stata/figures/cont_fig1.pdf&quot;) Figure 3.1: Simple mixed model marginal plot from Stata We will show how to code this in R below. The code is similar. 3.2.2 Model with treatment-time interaction A better solution would be to add a treatment-time interaction to the mixed model to loosen the assumption that the treatment effect is equal across time. In Stata, the model is coded as: use stata/rct, clear mixed contout i.trt i.time i.trt#i.time i.site covar || pid: (all strata combined) Performing EM optimization ... Performing gradient-based optimization: Iteration 0: Log likelihood = -603.47362 Iteration 1: Log likelihood = -603.47362 Computing standard errors ... Mixed-effects ML regression Number of obs = 392 Group variable: pid Number of groups = 98 Obs per group: min = 4 avg = 4.0 max = 4 Wald chi2(11) = 943.21 Log likelihood = -603.47362 Prob &gt; chi2 = 0.0000 ------------------------------------------------------------------------------ contout | Coefficient Std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- trt | Active | .1464841 .2563632 0.57 0.568 -.3559785 .6489468 | time | 1 | 1.516 .1889091 8.03 0.000 1.145745 1.886255 2 | 3.174 .1889091 16.80 0.000 2.803745 3.544255 3 | 4.092 .1889091 21.66 0.000 3.721745 4.462255 | trt#time | Active#1 | -1.186833 .2699264 -4.40 0.000 -1.715879 -.6577872 Active#2 | -2.25525 .2699264 -8.36 0.000 -2.784296 -1.726204 Active#3 | -2.862833 .2699264 -10.61 0.000 -3.391879 -2.333787 | site | 2 | .6526838 .2761649 2.36 0.018 .1114106 1.193957 3 | .5751011 .2484525 2.31 0.021 .0881431 1.062059 4 | .9060635 .2962487 3.06 0.002 .3254267 1.4867 | covar | .8633823 .0519317 16.63 0.000 .761598 .9651666 _cons | 13.77991 .3173239 43.43 0.000 13.15796 14.40185 ------------------------------------------------------------------------------ ------------------------------------------------------------------------------ Random-effects parameters | Estimate Std. err. [95% conf. interval] -----------------------------+------------------------------------------------ pid: Identity | var(_cons) | .7003448 .1331889 .4824292 1.016694 -----------------------------+------------------------------------------------ var(Residual) | .8921667 .0735847 .758997 1.048702 ------------------------------------------------------------------------------ LR test vs. linear model: chibar2(01) = 87.90 Prob &gt;= chibar2 = 0.0000 In R this model is coded as rct %&gt;% lmer(contout ~ trt + time + trt*time + site + covar + (1|pid),data=., REML=FALSE) %&gt;% summary(correlation=FALSE) Linear mixed model fit by maximum likelihood [&#39;lmerMod&#39;] Formula: contout ~ trt + time + trt * time + site + covar + (1 | pid) Data: . AIC BIC logLik deviance df.resid 1234.9 1290.5 -603.5 1206.9 378 Scaled residuals: Min 1Q Median 3Q Max -3.6736 -0.5555 0.0171 0.6023 2.4871 Random effects: Groups Name Variance Std.Dev. pid (Intercept) 0.7003 0.8369 Residual 0.8922 0.9445 Number of obs: 392, groups: pid, 98 Fixed effects: Estimate Std. Error t value (Intercept) 13.77991 0.31732 43.425 trtActive 0.14648 0.25636 0.571 time1 1.51600 0.18891 8.025 time2 3.17400 0.18891 16.802 time3 4.09200 0.18891 21.661 site2 0.65268 0.27616 2.363 site3 0.57510 0.24845 2.315 site4 0.90606 0.29625 3.058 covar 0.86338 0.05193 16.625 trtActive:time1 -1.18683 0.26993 -4.397 trtActive:time2 -2.25525 0.26993 -8.355 trtActive:time3 -2.86283 0.26993 -10.606 The problem with the results as presented both by Stata and R is that they are difficult to interpret. The solution is to use predictive margins and corresponding marginal plots. First we plot the predictive margins by treatment: use stata/rct, clear quietly mixed contout i.trt i.time i.trt#i.time i.site covar || pid: *Compute the predictive margins by time and treatment margins time#trt *Plot the predictive margins. Note that the arguments after the comma is just to prettify the plot. marginsplot, graphregion(color(white)) graphregion(color(white)) plotregion(color(white)) ytitle(&quot;Marginal estimates&quot;) ylabel(,nogrid) legend(region(color(none) lstyle(none)) cols(1) ring(0) bplacement(nwest)) title(&quot;&quot;) graph export stata/figures/cont_fig2.pdf, replace (all strata combined) Predictive margins Number of obs = 392 Expression: Linear prediction, fixed portion, predict() ------------------------------------------------------------------------------ | Delta-method | Margin std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- time#trt | 0#Placebo | 18.35274 .1789325 102.57 0.000 18.00204 18.70344 0#Active | 18.49923 .182642 101.29 0.000 18.14125 18.8572 1#Placebo | 19.86874 .1789325 111.04 0.000 19.51804 20.21944 1#Active | 18.82839 .182642 103.09 0.000 18.47042 19.18637 2#Placebo | 21.52674 .1789325 120.31 0.000 21.17604 21.87744 2#Active | 19.41798 .182642 106.32 0.000 19.06 19.77595 3#Placebo | 22.44474 .1789325 125.44 0.000 22.09404 22.79544 3#Active | 19.72839 .182642 108.02 0.000 19.37042 20.08637 ------------------------------------------------------------------------------ Variables that uniquely identify margins: time trt file stata/figures/cont_fig2.pdf saved as PDF format knitr::include_graphics(&quot;stata/figures/cont_fig2.pdf&quot;) Figure 3.2: Margins plot by Stata In R this can be achieved by: mod &lt;- lmer(contout ~ trt + time + trt*time + site + covar + (1|pid),data=rct, REML=FALSE) mod %&gt;% avg_predictions(variables = list(trt = c(&quot;Active&quot;, &quot;Placebo&quot;), time = c(&quot;0&quot;,&quot;1&quot;,&quot;2&quot;, &quot;3&quot;)) ) time trt Estimate Std. Error z Pr(&gt;|z|) S 2.5 % 97.5 % 0 Active 18.5 0.183 101 &lt;0.001 Inf 18.1 18.9 0 Placebo 18.4 0.179 103 &lt;0.001 Inf 18.0 18.7 1 Active 18.8 0.183 103 &lt;0.001 Inf 18.5 19.2 1 Placebo 19.9 0.179 111 &lt;0.001 Inf 19.5 20.2 2 Active 19.4 0.183 106 &lt;0.001 Inf 19.1 19.8 2 Placebo 21.5 0.179 120 &lt;0.001 Inf 21.2 21.9 3 Active 19.7 0.183 108 &lt;0.001 Inf 19.4 20.1 3 Placebo 22.4 0.179 125 &lt;0.001 Inf 22.1 22.8 Columns: trt, time, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high Type: response p &lt;- mod %&gt;% avg_predictions(variables = list(trt = c(&quot;Active&quot;, &quot;Placebo&quot;), time = c(&quot;0&quot;,&quot;1&quot;,&quot;2&quot;, &quot;3&quot;)) ) %&gt;% ggplot(aes(time, estimate, color=trt, group=trt)) + geom_point(position = position_dodge(0.04)) + geom_line() + geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width=.2, position = position_dodge(0.04)) + ylab(&quot;Estimate&quot;) + xlab(&quot;Time&quot;) + theme_classic() + theme(legend.position=c(0.1,0.9)) + scale_colour_brewer(palette = &quot;Set1&quot;, name = &quot;Treatment&quot;) p From this we can estimate the treatment difference at the different timepoints: use stata/rct, clear quietly mixed contout i.trt i.time i.trt#i.time i.site covar || pid: *Compute the marginal treatment differences margins time, dydx(trt) (all strata combined) Average marginal effects Number of obs = 392 Expression: Linear prediction, fixed portion, predict() dy/dx wrt: 1.trt ------------------------------------------------------------------------------ | Delta-method | dy/dx std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- 0.trt | (base outcome) -------------+---------------------------------------------------------------- 1.trt | time | 0 | .1464841 .2563632 0.57 0.568 -.3559785 .6489468 1 | -1.040349 .2563632 -4.06 0.000 -1.542812 -.5378865 2 | -2.108766 .2563632 -8.23 0.000 -2.611229 -1.606303 3 | -2.716349 .2563632 -10.60 0.000 -3.218812 -2.213887 ------------------------------------------------------------------------------ Note: dy/dx for factor levels is the discrete change from the base level. This can also be achieved in R by: mod %&gt;% avg_comparisons(variables = list(trt = c( &quot;Placebo&quot;, &quot;Active&quot;)), by = &quot;time&quot;) Term Contrast time Estimate Std. Error z Pr(&gt;|z|) trt mean(Active) - mean(Placebo) 0 0.146 0.256 0.571 0.568 trt mean(Active) - mean(Placebo) 1 -1.040 0.256 -4.058 &lt;0.001 trt mean(Active) - mean(Placebo) 2 -2.109 0.256 -8.226 &lt;0.001 trt mean(Active) - mean(Placebo) 3 -2.716 0.256 -10.596 &lt;0.001 S 2.5 % 97.5 % 0.8 -0.356 0.649 14.3 -1.543 -0.538 52.2 -2.611 -1.606 84.7 -3.219 -2.214 Columns: term, contrast, time, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted Type: response 3.2.3 Model with treatment-time interaction and baseline information Now, the above model is correct, and will provide unbiased estimates of the time and treatment specific means, including treatment differences at each timepoint. However, there is one piece of information left out of the model, and this is that we know there is no treatment difference at baseline. Thus, we can and should set this parameter to zero. In Stata, the model is implemented by using a constraint on the parameter space. This can only be done using -meglm-, which is a generalised version of -mixed-: use stata/rct, clear *Constrain the baseline treatment difference to be zero constraint 1 i1.trt#i0.time = 0 *Use the constraint in the model meglm contout i.trt#i.time i.site covar || pid:, constraints(1) quietly margins time#trt marginsplot, graphregion(color(white)) graphregion(color(white)) plotregion(color(white)) ytitle(&quot;Marginal estimates&quot;) ylabel(,nogrid) legend(region(color(none) lstyle(none)) cols(1) ring(0) bplacement(nwest)) title(&quot;&quot;) graph export stata/figures/cont_fig2.pdf, replace (all strata combined) Fitting fixed-effects model: Iteration 0: Log likelihood = -647.74846 Iteration 1: Log likelihood = -647.58931 Iteration 2: Log likelihood = -647.58924 Refining starting values: Grid node 0: Log likelihood = -627.10804 Fitting full model: Iteration 0: Log likelihood = -627.10804 Iteration 1: Log likelihood = -605.26422 Iteration 2: Log likelihood = -603.67119 Iteration 3: Log likelihood = -603.6368 Iteration 4: Log likelihood = -603.63676 Mixed-effects GLM Number of obs = 392 Family: Gaussian Link: Identity Group variable: pid Number of groups = 98 Obs per group: min = 4 avg = 4.0 max = 4 Integration method: mvaghermite Integration pts. = 7 Wald chi2(10) = 941.63 Log likelihood = -603.63676 Prob &gt; chi2 = 0.0000 ( 1) [contout]1.trt#0b.time = 0 ------------------------------------------------------------------------------ contout | Coefficient Std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- trt#time | Placebo#1 | 1.476264 .1757139 8.40 0.000 1.131872 1.820657 Placebo#2 | 3.134265 .1757139 17.84 0.000 2.789872 3.478658 Placebo#3 | 4.052264 .1757139 23.06 0.000 3.707872 4.396657 Active#0 | 0 (omitted) Active#1 | .3705578 .1787521 2.07 0.038 .0202101 .7209055 Active#2 | .960141 .1787521 5.37 0.000 .6097933 1.310489 Active#3 | 1.270558 .1787521 7.11 0.000 .9202101 1.620905 | site | 2 | .6561135 .2763683 2.37 0.018 .1144415 1.197785 3 | .5871323 .2478014 2.37 0.018 .1014504 1.072814 4 | .9130567 .2962843 3.08 0.002 .3323502 1.493763 | covar | .864888 .0519154 16.66 0.000 .7631356 .9666404 _cons | 13.83893 .3003121 46.08 0.000 13.25033 14.42753 -------------+---------------------------------------------------------------- pid | var(_cons)| .7020395 .1335678 .4835202 1.019315 -------------+---------------------------------------------------------------- var(e.cont~t)| .8925775 .0736384 .7593135 1.04923 ------------------------------------------------------------------------------ Variables that uniquely identify margins: time trt file stata/figures/cont_fig2.pdf saved as PDF format knitr::include_graphics(&quot;stata/figures/cont_fig2.pdf&quot;) Figure 3.3: Margins plot from Stata The estimates of the treatment differences at the different timepoints is then given by: use stata/rct, clear constraint 1 i1.trt#i0.time = 0 quietly meglm contout i.trt#i.time i.site covar || pid:, constraints(1) margins time, dydx(trt) (all strata combined) Average marginal effects Number of obs = 392 Model VCE: OIM Expression: Marginal predicted mean, predict() dy/dx wrt: 1.trt ------------------------------------------------------------------------------ | Delta-method | dy/dx std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- 0.trt | (base outcome) -------------+---------------------------------------------------------------- 1.trt | time | 0 | 0 (omitted) 1 | -1.105707 .2297171 -4.81 0.000 -1.555944 -.6554694 2 | -2.174124 .2297171 -9.46 0.000 -2.624361 -1.723886 3 | -2.781707 .2297171 -12.11 0.000 -3.231944 -2.331469 ------------------------------------------------------------------------------ Note: dy/dx for factor levels is the discrete change from the base level. The same can be accomplished in R by adding a third treatment level (level at baseline): rmixed4_2 &lt;- rct %&gt;% mutate(trt2 = trt) %&gt;% mutate(trt2 = fct_expand(trt2,&quot;0&quot;)) %&gt;% mutate(trt2 = if_else(time != &quot;0&quot;,trt2,factor(0) )) %&gt;% lmer(contout ~ time + trt2 + trt2*time + site + covar + (1|pid),data=., REML=FALSE) fixed-effect model matrix is rank deficient so dropping 5 columns / coefficients summary(rmixed4_2, correlation = FALSE) Linear mixed model fit by maximum likelihood [&#39;lmerMod&#39;] Formula: contout ~ time + trt2 + trt2 * time + site + covar + (1 | pid) Data: . AIC BIC logLik deviance df.resid 1233.3 1284.9 -603.6 1207.3 379 Scaled residuals: Min 1Q Median 3Q Max -3.6737 -0.5549 0.0147 0.6183 2.4434 Random effects: Groups Name Variance Std.Dev. pid (Intercept) 0.7020 0.8379 Residual 0.8926 0.9448 Number of obs: 392, groups: pid, 98 Fixed effects: Estimate Std. Error t value (Intercept) 13.83893 0.30031 46.082 time1 1.47626 0.17567 8.404 time2 3.13426 0.17567 17.842 time3 4.05226 0.17567 23.067 trt2Active -2.78171 0.22958 -12.116 site2 0.65611 0.27637 2.374 site3 0.58713 0.24780 2.369 site4 0.91306 0.29628 3.082 covar 0.86489 0.05192 16.660 time1:trt2Active 1.67600 0.26999 6.208 time2:trt2Active 0.60758 0.26999 2.250 fit warnings: fixed-effect model matrix is rank deficient so dropping 5 columns / coefficients pred &lt;- rmixed4_2 %&gt;% avg_predictions(variables = list(trt2 = c(&quot;Active&quot;, &quot;Placebo&quot;, &quot;0&quot;), time = c(&quot;0&quot;,&quot;1&quot;,&quot;2&quot;, &quot;3&quot;)) ) %&gt;% filter(!(trt2 == 0 &amp; time != 0)) %&gt;% filter(!(trt2 != 0 &amp; time == 0)) pred time trt2 Estimate Std. Error z Pr(&gt;|z|) S 2.5 % 97.5 % 0 0 18.4 0.128 144 &lt;0.001 Inf 18.2 18.7 1 Active 18.8 0.173 109 &lt;0.001 Inf 18.5 19.1 1 Placebo 19.9 0.170 117 &lt;0.001 Inf 19.6 20.2 2 Active 19.4 0.173 112 &lt;0.001 Inf 19.0 19.7 2 Placebo 21.6 0.170 127 &lt;0.001 Inf 21.2 21.9 3 Active 19.7 0.173 114 &lt;0.001 Inf 19.4 20.0 3 Placebo 22.5 0.170 132 &lt;0.001 Inf 22.1 22.8 Columns: trt2, time, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high Type: response The estimated marginal plot is then given by: p &lt;- pred %&gt;% mutate(trt2 = if_else(time == 0, &quot;Active&quot;, trt2)) %&gt;% bind_rows(pred %&gt;% filter(time == 0) %&gt;% mutate(trt2 = &quot;Placebo&quot;)) %&gt;% arrange( time, trt2) p %&gt;% ggplot(aes(time, estimate, color=trt2, group=trt2)) + geom_point(position = position_dodge(0.04)) + geom_line() + geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width=.2, position = position_dodge(0.04)) + ylab(&quot;Estimate&quot;) + xlab(&quot;Time&quot;) + theme_classic() + theme(legend.position=c(0.1,0.9)) + scale_colour_brewer(palette = &quot;Set1&quot;, name = &quot;Treatment&quot;) Note that the Stata and R output gives identical results, which is good! "],["dichotomous-endpoints.html", "Chapter 4 Dichotomous endpoints 4.1 Single follow-up 4.2 Repeated follow-up 4.3 Treatment-time interaction model", " Chapter 4 Dichotomous endpoints 4.1 Single follow-up For a single follow-up assessment of a dichotomous endpoint, the main method I use is a standard logistic regression. Then we can adjust for stratification factors in the randomisation in addition to other pre-specified covariates, both categorical and continuous. In the simulated example, we define that the primary outcome is the dichotomous categorical outcome at time 3. Note that usually the baseline status of all patients are negative for the outcome, so adjusting for baseline is not necessary. 4.1.1 Stata code use &quot;stata/rct&quot;, clear tabulate catout trt if time == 3, column logistic catout i.trt i.site covar if time==3, coef (all strata combined) +-------------------+ | Key | |-------------------| | frequency | | column percentage | +-------------------+ Categorica | Treatment l outcome | Placebo Active | Total -----------+----------------------+---------- Negative | 9 22 | 31 | 18.00 45.83 | 31.63 -----------+----------------------+---------- Positive | 41 26 | 67 | 82.00 54.17 | 68.37 -----------+----------------------+---------- Total | 50 48 | 98 | 100.00 100.00 | 100.00 Logistic regression Number of obs = 98 LR chi2(5) = 48.59 Prob &gt; chi2 = 0.0000 Log likelihood = -36.862204 Pseudo R2 = 0.3973 ------------------------------------------------------------------------------ catout | Coefficient Std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- trt | Active | -2.890301 .7850252 -3.68 0.000 -4.428922 -1.351679 | site | 2 | .7783404 .8580245 0.91 0.364 -.9033566 2.460037 3 | 1.423791 .7786531 1.83 0.067 -.1023412 2.949923 4 | .0253234 .8082887 0.03 0.975 -1.558893 1.60954 | covar | 1.001078 .2329461 4.30 0.000 .5445124 1.457644 _cons | -2.463577 .8925892 -2.76 0.006 -4.21302 -.7141344 ------------------------------------------------------------------------------ Note that the use the coef option to get the log odds ratio estimates. 4.1.2 R code rct &lt;- read_dta(&quot;stata/rct.dta&quot;) %&gt;% modify_at(c(&quot;trt&quot;,&quot;catout&quot;), haven::as_factor, levels = &quot;labels&quot;) %&gt;% modify_at(c(&quot;site&quot;,&quot;time&quot;), haven::as_factor) rct %&gt;% filter(time==3) %&gt;% glm(catout ~ trt + site + covar , data=., family = binomial) %&gt;% summary Call: glm(formula = catout ~ trt + site + covar, family = binomial, data = .) Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -2.46358 0.89259 -2.760 0.005780 ** trtActive -2.89030 0.78502 -3.682 0.000232 *** site2 0.77834 0.85802 0.907 0.364337 site3 1.42379 0.77865 1.829 0.067470 . site4 0.02532 0.80829 0.031 0.975007 covar 1.00108 0.23295 4.297 1.73e-05 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 122.318 on 97 degrees of freedom Residual deviance: 73.724 on 92 degrees of freedom AIC: 85.724 Number of Fisher Scoring iterations: 6 Not surprisingly, the estimates are identical. 4.1.3 Reporting Reporting for dichotomous endpoints is a bit tricky. The natural estimates from a logistic regression is odds and odds ratios, but these are less interpretable than risk differences or relative risk. As New England Journal of Medicine states in their Statistical Guidelines: “Odds ratios should be avoided, as they may overestimate the relative risks in many settings and be misinterpreted.” Fortunately, both Stata and R can estimate adjusted risk differences and relative risks from logistic regressions. 4.1.3.1 Stata code First we compute the average prediced marginal probabilities. Basically this is done by calculating the predicted probability of a positive outcome for each patient, under both treatments, and then averaging. The standard errors are computed by the delta method. use &quot;stata/rct&quot;, clear quietly logistic catout i.trt i.site covar if time==3, coef margins trt (all strata combined) Predictive margins Number of obs = 98 Model VCE: OIM Expression: Pr(catout), predict() ------------------------------------------------------------------------------ | Delta-method | Margin std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- trt | Placebo | .8499905 .0387218 21.95 0.000 .7740972 .9258839 Active | .5111833 .0533918 9.57 0.000 .4065374 .6158293 ------------------------------------------------------------------------------ The adjusted risk difference is calculated similarly. use &quot;stata/rct&quot;, clear quietly logistic catout i.trt i.site covar if time==3, coef margins, dydx(trt) (all strata combined) Average marginal effects Number of obs = 98 Model VCE: OIM Expression: Pr(catout), predict() dy/dx wrt: 1.trt ------------------------------------------------------------------------------ | Delta-method | dy/dx std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- trt | Active | -.3388072 .0661086 -5.13 0.000 -.4683777 -.2092367 ------------------------------------------------------------------------------ Note: dy/dx for factor levels is the discrete change from the base level. We see that the risk difference is the difference of the estimated marginal probabilities we computed previously. The relative risk is a bit more difficult to calculate, but not much. It uses the nlcom method to compute non-linear combinations of estimates. use &quot;stata/rct&quot;, clear quietly logistic catout i.trt i.site covar if time==3, coef quietly margins trt, post margins, coeflegend nlcom (ratio1: (_b[1.trt]/_b[0bn.trt])) (all strata combined) Predictive margins Number of obs = 98 Model VCE: OIM Expression: Pr(catout), predict() ------------------------------------------------------------------------------ | Margin Legend -------------+---------------------------------------------------------------- trt | Placebo | .8499905 _b[0bn.trt] Active | .5111833 _b[1.trt] ------------------------------------------------------------------------------ ratio1: (_b[1.trt]/_b[0bn.trt]) ------------------------------------------------------------------------------ | Coefficient Std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- ratio1 | .6013989 .0686524 8.76 0.000 .4668426 .7359552 ------------------------------------------------------------------------------ The trick is to know what goes into the _b[]-brackets, which will be revealed using the `coeflegend´-option. Note that I do not know the properties of this estimator, and it might be clever to check the estimates using bootstrap. Some journals require calculation of the number needed to treat (NNT), at least if the confidence interval of the adjusted risk difference does not include zero (for which the NNT is undefined). This is simply done by inverting the adjusted risk difference estimate (both point estimate and the confidence limits). 4.1.3.2 R code The average predicted marginal probabilities was previously not easily computed in R, but with the emergence of the very nice marginaleffects-package, this is now much easier: mod &lt;- rct %&gt;% filter(time == 3) %&gt;% glm(catout ~ trt + site + covar , data=., family = binomial) mod %&gt;% avg_predictions(variables = list(trt = c(&quot;Active&quot;, &quot;Placebo&quot;)), type = &quot;response&quot;) trt Estimate Std. Error z Pr(&gt;|z|) S 2.5 % 97.5 % Active 0.511 0.0534 9.57 &lt;0.001 69.7 0.407 0.616 Placebo 0.850 0.0387 21.95 &lt;0.001 352.4 0.774 0.926 Columns: trt, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high Type: response We notice that the estimates are equal to the Stata output.. Another option is to bootstrap the predicted marginal predictions: library(boot) fpred &lt;- function(formula, data, indices){ d &lt;- data[indices,] fit &lt;- glm(formula, data = d, family = binomial) pred &lt;- prediction(fit,data = d, at = list(trt = c(&quot;Active&quot;, &quot;Placebo&quot;))) %&gt;% as_tibble %&gt;% group_by(trt) %&gt;% summarise(mean = mean(fitted)) %&gt;% ungroup() %&gt;% mutate(name = paste0(trt)) %&gt;% select(name,mean) %&gt;% spread(name,mean) %&gt;% as_vector return(pred) } data &lt;- filter(rct, time == 3) result &lt;- boot(data = data, statistic = fpred, R = 10000, formula = catout ~ trt + site + covar, parallel = &quot;multicore&quot;, ncpus = 4) %&gt;% tidy(conf.int = TRUE) Error in prediction(fit, data = d, at = list(trt = c(&quot;Active&quot;, &quot;Placebo&quot;))): could not find function &quot;prediction&quot; result %&gt;% select(-bias) %&gt;% knitr::kable(digits = 3) term statistic std.error conf.low conf.high Active 0.601 0.081 0.445 0.763 We see that the estimates are identical to the Stata estimates, although the standard errors and confidence limits are a bit different. But I actually think the bootstrap estimates are better. The estimated marginal risk difference in R is computed using the marginaleffects-package again. rlogistic &lt;- rct %&gt;% filter(time==3) %&gt;% glm(catout ~ trt + site + covar , data=., family = binomial) rlogistic %&gt;% avg_comparisons(variables = list(trt = c(&quot;Active&quot;, &quot;Placebo&quot;)), type = &quot;response&quot;) Term Contrast Estimate Std. Error z Pr(&gt;|z|) S 2.5 % 97.5 % trt Placebo - Active 0.339 0.0661 5.13 &lt;0.001 21.7 0.209 0.468 Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high Type: response We see that the estimates are identical to the Stata estimates. The relative risk is very easily computed in R using the marginaleffects-package: rlogistic &lt;- rct %&gt;% filter(time==3) %&gt;% glm(catout ~ trt + site + covar , data=., family = binomial) rlogistic %&gt;% avg_comparisons(variables = list(trt = c(&quot;Active&quot;, &quot;Placebo&quot;)), type = &quot;response&quot;, comparison = &quot;ratioavg&quot;) Term Contrast Estimate Std. Error z Pr(&gt;|z|) S 2.5 % trt mean(Placebo) / mean(Active) 1.66 0.19 8.76 &lt;0.001 58.8 1.29 97.5 % 2.03 Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted Type: response The estimate is the inverse of the Stata estimate, and the confidence limits are very similar. There is probably a slight difference in how these are computed. This is possible to do also by bootstrapping, but it is a bit more complicated: library(boot) library(prediction) fpred &lt;- function(formula, data, indices){ d &lt;- data[indices,] fit &lt;- glm(formula, data = d, family = binomial) pred &lt;- prediction(fit,data = d, at = list(trt = c(&quot;Active&quot;, &quot;Placebo&quot;))) %&gt;% as_tibble %&gt;% group_by(trt) %&gt;% summarise(mean = mean(fitted)) %&gt;% ungroup() %&gt;% mutate(name = paste0(trt)) %&gt;% select(name,mean) %&gt;% spread(name,mean) %&gt;% as_vector return(pred[&quot;Active&quot;]/pred[&quot;Placebo&quot;]) } data &lt;- filter(rct, time == 3) result &lt;- boot(data = data, statistic = fpred, R = 10000, formula = catout ~ trt + site + covar, parallel = &quot;multicore&quot;, ncpus = 4) %&gt;% tidy(conf.int = TRUE) result %&gt;% select(-bias) %&gt;% knitr::kable(digits = 3) term statistic std.error conf.low conf.high Active 0.601 0.081 0.45 0.77 4.2 Repeated follow-up When there are repeated dichotomous endpoints, there are usually two methods available, either the generalized estimating equations method or the generalized mixed model method. I prefer the mixed model approach because it has better missing data properties, and I like that the parameter estimates are interpretable conditional on the subject. In my mind it is more aligned to a causal interpretation. I will show how to do the mixed logistic regression model. We skip the simple model and go straight to a model with treatment-time interaction. Note that usually a dichotomous endpoint all have the same value at baseline (all subjects are in the same state), thus we rarely include the baseline. The model is a simple random intercept model, but it could of course also be expanded to a random intercept and slope model. 4.3 Treatment-time interaction model In Stata, the model is coded as: use &quot;stata/rct&quot;, clear bysort time: tabulate catout trt, column melogit catout i.trt i.site covar i.time i.trt#i.time if time != 0 || pid: (all strata combined) ------------------------------------------------------------------------------- -&gt; time = 0 +-------------------+ | Key | |-------------------| | frequency | | column percentage | +-------------------+ Categorica | Treatment l outcome | Placebo Active | Total -----------+----------------------+---------- Negative | 50 48 | 98 | 100.00 100.00 | 100.00 -----------+----------------------+---------- Total | 50 48 | 98 | 100.00 100.00 | 100.00 ------------------------------------------------------------------------------- -&gt; time = 1 +-------------------+ | Key | |-------------------| | frequency | | column percentage | +-------------------+ Categorica | Treatment l outcome | Placebo Active | Total -----------+----------------------+---------- Negative | 24 32 | 56 | 48.00 66.67 | 57.14 -----------+----------------------+---------- Positive | 26 16 | 42 | 52.00 33.33 | 42.86 -----------+----------------------+---------- Total | 50 48 | 98 | 100.00 100.00 | 100.00 ------------------------------------------------------------------------------- -&gt; time = 2 +-------------------+ | Key | |-------------------| | frequency | | column percentage | +-------------------+ Categorica | Treatment l outcome | Placebo Active | Total -----------+----------------------+---------- Negative | 12 29 | 41 | 24.00 60.42 | 41.84 -----------+----------------------+---------- Positive | 38 19 | 57 | 76.00 39.58 | 58.16 -----------+----------------------+---------- Total | 50 48 | 98 | 100.00 100.00 | 100.00 ------------------------------------------------------------------------------- -&gt; time = 3 +-------------------+ | Key | |-------------------| | frequency | | column percentage | +-------------------+ Categorica | Treatment l outcome | Placebo Active | Total -----------+----------------------+---------- Negative | 9 22 | 31 | 18.00 45.83 | 31.63 -----------+----------------------+---------- Positive | 41 26 | 67 | 82.00 54.17 | 68.37 -----------+----------------------+---------- Total | 50 48 | 98 | 100.00 100.00 | 100.00 Fitting fixed-effects model: Iteration 0: Log likelihood = -133.59899 Iteration 1: Log likelihood = -129.32428 Iteration 2: Log likelihood = -129.32244 Iteration 3: Log likelihood = -129.32244 Refining starting values: Grid node 0: Log likelihood = -130.87679 Fitting full model: Iteration 0: Log likelihood = -130.87679 Iteration 1: Log likelihood = -129.7867 Iteration 2: Log likelihood = -129.37214 Iteration 3: Log likelihood = -129.31054 Iteration 4: Log likelihood = -129.31042 Iteration 5: Log likelihood = -129.31042 Mixed-effects logistic regression Number of obs = 294 Group variable: pid Number of groups = 98 Obs per group: min = 3 avg = 3.0 max = 3 Integration method: mvaghermite Integration pts. = 7 Wald chi2(9) = 57.65 Log likelihood = -129.31042 Prob &gt; chi2 = 0.0000 ------------------------------------------------------------------------------ catout | Coefficient Std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- trt | Active | -1.445692 .5336445 -2.71 0.007 -2.491616 -.3997679 | site | 2 | -.0293421 .4666747 -0.06 0.950 -.9440077 .8853234 3 | .72617 .4145006 1.75 0.080 -.0862363 1.538576 4 | .5185491 .4721013 1.10 0.272 -.4067524 1.443851 | covar | .9174909 .1319527 6.95 0.000 .6588684 1.176113 | time | 2 | 1.787348 .5856394 3.05 0.002 .6395156 2.93518 3 | 2.365878 .6353582 3.72 0.000 1.120599 3.611157 | trt#time | Active#2 | -1.406754 .7657322 -1.84 0.066 -2.907561 .0940536 Active#3 | -1.127376 .785537 -1.44 0.151 -2.667 .4122484 | _cons | -4.424402 .7595232 -5.83 0.000 -5.91304 -2.935764 -------------+---------------------------------------------------------------- pid | var(_cons)| .0684106 .4545936 1.51e-07 31004.17 ------------------------------------------------------------------------------ LR test vs. logistic model: chibar2(01) = 0.02 Prob &gt;= chibar2 = 0.4384 In R, this model is coded as: library(lme4) rct %&gt;% filter(time != 0) %&gt;% glmer(catout ~ trt + time + trt*time + site + covar + (1|pid), data = ., family = binomial, nAGQ = 7) %&gt;% summary() Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 7) [glmerMod] Family: binomial ( logit ) Formula: catout ~ trt + time + trt * time + site + covar + (1 | pid) Data: . AIC BIC logLik deviance df.resid 280.6 321.1 -129.3 258.6 283 Scaled residuals: Min 1Q Median 3Q Max -2.8902 -0.5490 0.1407 0.5132 5.6565 Random effects: Groups Name Variance Std.Dev. pid (Intercept) 0.06842 0.2616 Number of obs: 294, groups: pid, 98 Fixed effects: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -4.42440 0.75952 -5.825 5.70e-09 *** trtActive -1.44556 0.53364 -2.709 0.006751 ** time2 1.78740 0.58564 3.052 0.002273 ** time3 2.36568 0.63534 3.724 0.000196 *** site2 -0.02946 0.46667 -0.063 0.949661 site3 0.72598 0.41449 1.751 0.079861 . site4 0.51846 0.47210 1.098 0.272110 covar 0.91750 0.13195 6.953 3.57e-12 *** trtActive:time2 -1.40690 0.76574 -1.837 0.066163 . trtActive:time3 -1.12718 0.78553 -1.435 0.151305 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Correlation of Fixed Effects: (Intr) trtAct time2 time3 site2 site3 site4 covar trtA:2 trtActive -0.117 time2 -0.555 0.349 time3 -0.604 0.295 0.475 site2 -0.188 -0.031 0.029 0.042 site3 -0.292 -0.115 0.059 0.077 0.477 site4 -0.306 -0.061 0.052 0.078 0.398 0.462 covar -0.818 -0.226 0.293 0.373 -0.074 0.032 0.086 trtActv:tm2 0.385 -0.601 -0.750 -0.343 -0.020 -0.031 -0.037 -0.181 trtActv:tm3 0.363 -0.594 -0.336 -0.745 -0.029 -0.015 -0.048 -0.161 0.470 4.3.1 Reporting Plotting i Stata use stata/rct, clear quietly melogit catout i.trt i.site covar i.time i.trt#i.time if time != 0 || pid: *Compute the predictive margins by time and treatment margins time#trt *Plot the predictive margins. Note that the arguments after the comma is just to prettify the plot. marginsplot, graphregion(color(white)) graphregion(color(white)) plotregion(color(white)) ytitle(&quot;Marginal estimates&quot;) ylabel(,nogrid) legend(region(color(none) lstyle(none)) cols(1) ring(0) bplacement(nwest)) title(&quot;&quot;) graph export stata/figures/cat_fig1.pdf, replace (all strata combined) Predictive margins Number of obs = 294 Model VCE: OIM Expression: Marginal predicted mean, predict() ------------------------------------------------------------------------------ | Delta-method | Margin std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- time#trt | 1#Placebo | .5476187 .0577701 9.48 0.000 .4343913 .660846 1#Active | .3187847 .0540835 5.89 0.000 .2127831 .4247863 2#Placebo | .7897137 .0463852 17.03 0.000 .6988004 .880627 2#Active | .3770772 .0557815 6.76 0.000 .2677475 .4864068 3#Placebo | .8467085 .0410465 20.63 0.000 .7662588 .9271581 3#Active | .5147246 .0571038 9.01 0.000 .4028032 .626646 ------------------------------------------------------------------------------ Variables that uniquely identify margins: time trt file stata/figures/cat_fig1.pdf saved as PDF format knitr::include_graphics(&quot;stata/figures/cat_fig1.pdf&quot;) Figure 4.1: Margins plot by Stata The same in R using the marginaleffects-package: mod &lt;- rct %&gt;% filter(time != 0) %&gt;% glmer(catout ~ trt + time + trt*time + site + covar + (1|pid), data = ., family = binomial, nAGQ = 7) pred &lt;- mod %&gt;% avg_predictions(variables = list(trt = c( &quot;Placebo&quot;, &quot;Active&quot;), time = c(&quot;1&quot;,&quot;2&quot;, &quot;3&quot;)), type = &quot;response&quot;) Warning: For this model type, `marginaleffects` only takes into account the uncertainty in fixed-effect parameters. You can use the `re.form=NA` argument to acknowledge this explicitly and silence this warning. pred time trt Estimate Std. Error z Pr(&gt;|z|) S 2.5 % 97.5 % 1 Placebo 0.548 0.0580 9.45 &lt;0.001 67.9 0.434 0.662 1 Active 0.318 0.0548 5.80 &lt;0.001 27.2 0.210 0.425 2 Placebo 0.791 0.0462 17.13 &lt;0.001 216.1 0.701 0.882 2 Active 0.376 0.0561 6.70 &lt;0.001 35.5 0.266 0.486 3 Placebo 0.848 0.0411 20.62 &lt;0.001 311.3 0.767 0.929 3 Active 0.515 0.0578 8.91 &lt;0.001 60.8 0.402 0.628 Columns: trt, time, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high Type: response The estimated marginal plot is then given by: pred %&gt;% ggplot(aes(time, estimate, color=trt, group=trt)) + geom_point(position = position_dodge(0.04)) + geom_line() + geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width=.2, position = position_dodge(0.04)) + ylab(&quot;Estimate&quot;) + xlab(&quot;Time&quot;) + theme_classic() + theme(legend.position=c(0.1,0.9)) + scale_colour_brewer(palette = &quot;Set1&quot;, name = &quot;Treatment&quot;) The treatment differences at different timepoints are then calculated with: use &quot;stata/rct&quot;, clear quietly melogit catout i.trt i.site covar i.time i.trt#i.time if time != 0 || pid: margins time, dydx(trt) (all strata combined) Average marginal effects Number of obs = 294 Model VCE: OIM Expression: Marginal predicted mean, predict() dy/dx wrt: 1.trt ------------------------------------------------------------------------------ | Delta-method | dy/dx std. err. z P&gt;|z| [95% conf. interval] -------------+---------------------------------------------------------------- 0.trt | (base outcome) -------------+---------------------------------------------------------------- 1.trt | time | 1 | -.228834 .079152 -2.89 0.004 -.383969 -.0736989 2 | -.4126365 .0726801 -5.68 0.000 -.5550869 -.2701861 3 | -.3319839 .070613 -4.70 0.000 -.4703829 -.1935849 ------------------------------------------------------------------------------ Note: dy/dx for factor levels is the discrete change from the base level. In R this is done with the marginaleffects-package: mod &lt;- rct %&gt;% filter(time != 0) %&gt;% glmer(catout ~ trt + time + trt*time + site + covar + (1|pid), data = ., family = binomial, nAGQ = 7) mod %&gt;% avg_comparisons(variables = list(trt = c(&quot;Active&quot;, &quot;Placebo&quot;)), by = &quot;time&quot;, type = &quot;response&quot;, re.form = NA) Term Contrast time Estimate Std. Error z Pr(&gt;|z|) S trt mean(Placebo) - mean(Active) 1 0.230 0.0797 2.89 0.00386 8.0 trt mean(Placebo) - mean(Active) 2 0.414 0.0728 5.69 &lt; 0.001 26.2 trt mean(Placebo) - mean(Active) 3 0.333 0.0704 4.73 &lt; 0.001 18.7 2.5 % 97.5 % 0.0741 0.387 0.2717 0.557 0.1947 0.471 Columns: term, contrast, time, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted Type: response We see the results are slightly different to the Stata results, but the differences are small. "],["time-to-event-analyses.html", "Chapter 5 Time to event analyses", " Chapter 5 Time to event analyses To be done "],["sample-size-calculations.html", "Chapter 6 Sample size calculations", " Chapter 6 Sample size calculations To be done "],["references.html", "References", " References "]]
